{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90107ae1",
   "metadata": {},
   "source": [
    "# Ex 6번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db0821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc145f3",
   "metadata": {},
   "source": [
    "여기서 굳이 sentences로 해서 담는 이유는 ... word_list는 왜 나와...? 그냥 그런 기능이 있는거야?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27edeca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42773b1",
   "metadata": {},
   "source": [
    "위의 결과로 단어 10개짜리의 작은 딕셔너리가 만들어졌다. \n",
    "텍스트 데이터를 숫자로 바꾸려면 위의 딕셔너리를 {텍스트:인덱스} 구조로 만들어야한다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de986ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8c8e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df777a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076c622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c44af",
   "metadata": {},
   "source": [
    "반대로, encode된 벡터를 decode하여 다시 원래 텍스트 데이터로 복구할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20516ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec87cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce033bc6",
   "metadata": {},
   "source": [
    "정의가 된 함수들은 이후에도 반복해서 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34531e",
   "metadata": {},
   "source": [
    "# Embedding layer의 등장\n",
    " - Tensorflow, Pytorch등의 딥러닝 프레임워크들은 의미 벡터 파라미터를 구현한 Embedding layer를 제공한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44e5ea7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨 :  1\n",
      "1번 인덱스가 뭔가요 :  the\n",
      "the는 몇번 인덱스인가요 :  1\n",
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_decoded_sentence(raw_sentence,index_to_word):\n",
    "    return ' '.join(index_to_word[idx] if idx in index_to_word else \"<UNK>\" for idx in raw_sentence[1:])\n",
    "\n",
    "def get_decoded_sentences(raw_sens,index_to_word):\n",
    "    return [get_decoded_sentence(sentence,index_to_word) for sentence in raw_sens]\n",
    "\n",
    "imdb = tf.keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(x_train[0])\n",
    "print(\"라벨 : \",y_train[0])\n",
    "\n",
    "\n",
    "#제공되는 딕셔너리를 저장합니다.\n",
    "word_to_index = imdb.get_word_index()\n",
    "#제공된 딕셔너리를 이용해 idx에서 word로 변환하는 딕셔너리를 정의합니다.\n",
    "index_to_word = {index:word for word,index in word_to_index.items()}\n",
    "print(\"1번 인덱스가 뭔가요 : \",index_to_word[1])\n",
    "print(\"the는 몇번 인덱스인가요 : \",word_to_index['the'])\n",
    "\n",
    "print(get_decoded_sentence(x_train[0],index_to_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41845937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#매핑된 인덱스를 3씩 올려줍니다.\n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "#사전에 정의된 인덱스는 따로 처리!\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "#재정의된 word_to_index에 맞게 재정의해줍니다.\n",
    "index_to_word = {index:word for word,index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d98939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#보정된 딕셔너리로 번역된 문장입니다.\n",
    "print(get_decoded_sentence(x_train[0],index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85efe7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   13  235 5396    0]\n",
      " [   1   13 1900 6803    0]\n",
      " [   1  150   13  235  654]]\n",
      "tf.Tensor(\n",
      "[[[-0.04260198  0.02759534 -0.02231408 -0.03350891]\n",
      "  [ 0.02812756 -0.04048174  0.01492769  0.00747962]\n",
      "  [-0.00561512 -0.0238874   0.03723601  0.00479044]\n",
      "  [ 0.03613876 -0.00217115  0.02994775 -0.0298324 ]\n",
      "  [ 0.0066942   0.02262983 -0.04871633  0.03764108]]\n",
      "\n",
      " [[-0.04260198  0.02759534 -0.02231408 -0.03350891]\n",
      "  [ 0.02812756 -0.04048174  0.01492769  0.00747962]\n",
      "  [ 0.03809508  0.04423609 -0.02055256 -0.0400108 ]\n",
      "  [-0.00977837 -0.00897509 -0.01505147 -0.0397712 ]\n",
      "  [ 0.0066942   0.02262983 -0.04871633  0.03764108]]\n",
      "\n",
      " [[-0.04260198  0.02759534 -0.02231408 -0.03350891]\n",
      "  [-0.01992855  0.01148657 -0.01576657 -0.01753913]\n",
      "  [ 0.02812756 -0.04048174  0.01492769  0.00747962]\n",
      "  [-0.00561512 -0.0238874   0.03723601  0.00479044]\n",
      "  [-0.04815475 -0.02267376 -0.04592284 -0.02365329]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69bd5b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이의 평균 : 234.75892\n",
      "문장 길이의 최대 : 2494\n",
      "문장 길이의 표준편차 : 172.91149458735703\n",
      "전체 문장의 0.94536%가 maxlen값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_data_text = list(x_train)+list(x_test)\n",
    "#문장의 길이를 리스트로 저장한뒤 numpy함수를 사용하기 위해 numpy 리스트로 변환합니다.\n",
    "num_tokens = [len(token) for token in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print(\"문장 길이의 평균 :\", np.mean(num_tokens))\n",
    "print(\"문장 길이의 최대 :\", np.max(num_tokens))\n",
    "print(\"문장 길이의 표준편차 :\", np.std(num_tokens))\n",
    "#임시로 maxlen을 평균 + 2 * 표준편차라고 한다면,\n",
    "max_tokens = np.mean(num_tokens)+2*np.std(num_tokens)\n",
    "#실수형 데이터를 정수로 바꿔줍니다.\n",
    "maxlen = int(max_tokens)\n",
    "print(\"전체 문장의 {}%가 maxlen값 이내에 포함됩니다.\".format(np.sum(num_tokens<max_tokens)/len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10cc694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000, 580)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    1   14\n",
      "   22   16   43  530  973 1622 1385   65  458 4468   66 3941    4  173\n",
      "   36  256    5   25  100   43  838  112   50  670    2    9   35  480\n",
      "  284    5  150    4  172  112  167    2  336  385   39    4  172 4536\n",
      " 1111   17  546   38   13  447    4  192   50   16    6  147 2025   19\n",
      "   14   22    4 1920 4613  469    4   22   71   87   12   16   43  530\n",
      "   38   76   15   13 1247    4   22   17  515   17   12   16  626   18\n",
      "    2    5   62  386   12    8  316    8  106    5    4 2223 5244   16\n",
      "  480   66 3785   33    4  130   12   16   38  619    5   25  124   51\n",
      "   36  135   48   25 1415   33    6   22   12  215   28   77   52    5\n",
      "   14  407   16   82    2    8    4  107  117 5952   15  256    4    2\n",
      "    7 3766    5  723   36   71   43  530  476   26  400  317   46    7\n",
      "    4    2 1029   13  104   88    4  381   15  297   98   32 2071   56\n",
      "   26  141    6  194 7486   18    4  226   22   21  134  476   26  480\n",
      "    5  144   30 5535   18   51   36   28  224   92   25  104    4  226\n",
      "   65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n",
      "   15   16 5345   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "#얻은 maxlen을 이용해 문장의 길이를 통일시킵니다.\n",
    "print(x_train.shape)\n",
    "#padding을 추가하는 위치는 post와 pre가 있습니다.\n",
    "pre_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                       maxlen=maxlen)\n",
    "pre_x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                       maxlen=maxlen)\n",
    "post_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                       maxlen=maxlen)\n",
    "post_x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                       maxlen=maxlen)\n",
    "print(pre_x_train.shape)\n",
    "print(pre_x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a060ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 훈련을 위해 데이터를 나눠줍니다.\n",
    "#검증데이터\n",
    "pre_x_val = pre_x_train[:10000]\n",
    "post_x_val = post_x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "#학습데이터\n",
    "pre_partial_x_train = pre_x_train[10000:]\n",
    "post_partial_x_train = post_x_train[10000:]\n",
    "y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc04bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 16\n",
    "#데이터에 따라 모델을 각각 준비합니다.\n",
    "pre_model = tf.keras.Sequential()\n",
    "pre_model.add(tf.keras.layers.Embedding(vocab_size,word_vector_dim,input_shape=(None,)))\n",
    "pre_model.add(tf.keras.layers.LSTM(8))\n",
    "pre_model.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "pre_model.add(tf.keras.layers.Dense(1,activation='sigmoid'))#출력값은 0,1 둘 중 하나면 됩니다\n",
    "\n",
    "post_model = tf.keras.Sequential()\n",
    "post_model.add(tf.keras.layers.Embedding(vocab_size,word_vector_dim,input_shape=(None,)))\n",
    "post_model.add(tf.keras.layers.LSTM(8))\n",
    "post_model.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "post_model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd43add",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d820543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 5s 48ms/step - loss: 0.6919 - accuracy: 0.5346 - val_loss: 0.6894 - val_accuracy: 0.6063\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6805 - accuracy: 0.6629 - val_loss: 0.6696 - val_accuracy: 0.6593\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6125 - accuracy: 0.7493 - val_loss: 0.5390 - val_accuracy: 0.8081\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.4845 - accuracy: 0.8471 - val_loss: 0.4713 - val_accuracy: 0.8350\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.3892 - accuracy: 0.8862 - val_loss: 0.4346 - val_accuracy: 0.8373\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.3217 - accuracy: 0.9065 - val_loss: 0.3739 - val_accuracy: 0.8575\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2670 - accuracy: 0.9231 - val_loss: 0.3649 - val_accuracy: 0.8532\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2328 - accuracy: 0.9325 - val_loss: 0.3837 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2286 - accuracy: 0.9281 - val_loss: 0.3642 - val_accuracy: 0.8477\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2037 - accuracy: 0.9375 - val_loss: 0.4055 - val_accuracy: 0.8434\n"
     ]
    }
   ],
   "source": [
    "pre_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "pre_history = pre_model.fit(pre_partial_x_train,\n",
    "                           y_train,\n",
    "                           epochs=epochs,\n",
    "                           batch_size = 512,\n",
    "                           validation_data=(pre_x_val,y_val),\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ba5b1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 3s 42ms/step - loss: 0.6931 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5015\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6928 - accuracy: 0.5133 - val_loss: 0.6931 - val_accuracy: 0.5011\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6924 - accuracy: 0.5079 - val_loss: 0.6929 - val_accuracy: 0.5011\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6909 - accuracy: 0.5083 - val_loss: 0.6918 - val_accuracy: 0.5024\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6854 - accuracy: 0.5229 - val_loss: 0.6882 - val_accuracy: 0.5079\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6807 - accuracy: 0.5319 - val_loss: 0.6866 - val_accuracy: 0.5109\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6695 - accuracy: 0.5321 - val_loss: 0.6871 - val_accuracy: 0.5106\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6823 - accuracy: 0.5306 - val_loss: 0.6907 - val_accuracy: 0.5050\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6794 - accuracy: 0.5317 - val_loss: 0.6890 - val_accuracy: 0.5071\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6749 - accuracy: 0.5325 - val_loss: 0.6886 - val_accuracy: 0.5073\n"
     ]
    }
   ],
   "source": [
    "post_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "post_history = post_model.fit(post_partial_x_train,\n",
    "                           y_train,\n",
    "                           epochs=epochs,\n",
    "                           batch_size = 512,\n",
    "                           validation_data=(post_x_val,y_val),\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66b60b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.4183 - accuracy: 0.8392\n",
      "782/782 - 5s - loss: 0.6892 - accuracy: 0.5105\n",
      "padding의 위치에 따른 정확도 비교 -> pre : 83% post : 51%\n"
     ]
    }
   ],
   "source": [
    "pre_loss,pre_acc = pre_model.evaluate(pre_x_test,  y_test, verbose=2)\n",
    "post_loss,post_acc = post_model.evaluate(post_x_test,  y_test, verbose=2)\n",
    "print(\"padding의 위치에 따른 정확도 비교 -> pre : {}% post : {}%\".format(int(pre_acc*100),\n",
    "                                                            int(post_acc*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aeeb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습한 임베딩 파라미터를 파일에 저장합니다.\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path,'w')\n",
    "#몇개의 벡터를 얼마 사이즈로 쓸 것인지 타이틀로 기록합니다.\n",
    "f.write('{} {}\\n'.format(vocab_size-4,word_vector_dim))\n",
    "\n",
    "vectors = pre_model.get_weights()[0]\n",
    "# 첫 특수문자 4개를 제외하고 모두 파일에 기록합니다.\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i],' '.join(map(str,list(vectors[i,:])))))\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f79589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05342961,  0.04084945,  0.07172848,  0.03279585, -0.00883288,\n",
       "        0.06762367,  0.0192168 , -0.01535941,  0.03656299,  0.00533588,\n",
       "        0.02511191,  0.03816698, -0.07383454, -0.00558129,  0.01663273,\n",
       "        0.01806433], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors as w2v\n",
    "#파일로 된 워드 임베딩을 불러옵니다.\n",
    "word_vectors = w2v.load_word2vec_format(word2vec_file_path,binary = False)\n",
    "#computer의 워드 벡터를 확인합시다.\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c4f9c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vulnerable', 0.9564344882965088),\n",
       " ('blake', 0.9476271271705627),\n",
       " ('9', 0.9458087682723999),\n",
       " ('owns', 0.9451361894607544),\n",
       " ('country', 0.9450594782829285),\n",
       " ('thanks', 0.9423068165779114),\n",
       " ('ages', 0.9414801001548767),\n",
       " ('7', 0.9391072988510132),\n",
       " ('amazing', 0.9383803009986877),\n",
       " ('lived', 0.9381442666053772)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07220b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'6 ')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/3146946651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword2vec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'computer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#300차원의 워드 벡터입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1963\u001b[0m             \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0;31m# jump to the next member, if there is one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_gzip_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36m_read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'\\037\\213'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not a gzipped file (%r)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         (method, flag,\n",
      "\u001b[0;31mBadGzipFile\u001b[0m: Not a gzipped file (b'6 ')"
     ]
    }
   ],
   "source": [
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = w2v.load_word2vec_format(word2vec_path,binary = True,limit = 1000000)\n",
    "vector = word2vec['computer']\n",
    "#300차원의 워드 벡터입니다.\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d91df70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/4063403497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"love\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a50af2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/28683427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#단어사전에 존재하는 단어별 워드 벡터를 복사합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 300\n",
    "embedding_matrix = np.random.rand(vocab_size,word_vector_dim)\n",
    "#단어사전에 존재하는 단어별 워드 벡터를 복사합니다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f09b97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "416c9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))\n",
    "model.add(tf.keras.layers.LSTM(8))\n",
    "model.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e4170e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 4s 71ms/step - loss: 0.6913 - accuracy: 0.5301 - val_loss: 0.6872 - val_accuracy: 0.5941\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.6704 - accuracy: 0.6219 - val_loss: 0.6431 - val_accuracy: 0.6684\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.6212 - accuracy: 0.7241 - val_loss: 0.6005 - val_accuracy: 0.7393\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.5695 - accuracy: 0.7843 - val_loss: 0.5793 - val_accuracy: 0.7390\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.5570 - accuracy: 0.7851 - val_loss: 0.6117 - val_accuracy: 0.6735\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.6710 - accuracy: 0.5810 - val_loss: 0.6507 - val_accuracy: 0.6151\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.5564 - accuracy: 0.7536 - val_loss: 0.5887 - val_accuracy: 0.8044\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.4833 - accuracy: 0.8531 - val_loss: 0.5049 - val_accuracy: 0.8126\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.4473 - accuracy: 0.8805 - val_loss: 0.4933 - val_accuracy: 0.8173\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.4313 - accuracy: 0.8872 - val_loss: 0.4739 - val_accuracy: 0.8307\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10\n",
    "\n",
    "history = model.fit(pre_partial_x_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(pre_x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "120c42df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 6s - loss: 0.4806 - accuracy: 0.8320\n",
      "모델의 정확도는 83% 입니다.\n"
     ]
    }
   ],
   "source": [
    "model_loss,model_acc = model.evaluate(pre_x_test,y_test,verbose=2)\n",
    "print(\"모델의 정확도는 {}% 입니다.\".format(int(model_acc*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23e510",
   "metadata": {},
   "source": [
    "주의해야 할 점이 있습니다. \n",
    "\n",
    "Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 합니다. \n",
    "\n",
    "raw_inputs의 3개 벡터의 길이는 각각 4, 4, 5입니다.\n",
    "\n",
    "Tensorflow에서는 tf.keras.preprocessing.sequence.pad_sequences라는 \n",
    "\n",
    "편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공합니다.\n",
    "    \n",
    "    \n",
    "<오류 발생>\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "    \n",
    "<오류 수정>\n",
    "    \n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e855202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.0433997  -0.03496414  0.02270115  0.03573449]\n",
      "  [-0.04805122 -0.04611958 -0.00368042 -0.02210575]\n",
      "  [-0.00956595 -0.0129882  -0.01961517  0.02310673]\n",
      "  [ 0.00462831 -0.01772109 -0.01295043 -0.00085523]\n",
      "  [-0.00787749  0.00356957  0.02474667 -0.03136282]]\n",
      "\n",
      " [[-0.0433997  -0.03496414  0.02270115  0.03573449]\n",
      "  [-0.04805122 -0.04611958 -0.00368042 -0.02210575]\n",
      "  [-0.049557   -0.00342374  0.02751136  0.03803409]\n",
      "  [ 0.0317567  -0.03994334  0.03510097 -0.02485411]\n",
      "  [-0.00787749  0.00356957  0.02474667 -0.03136282]]\n",
      "\n",
      " [[-0.0433997  -0.03496414  0.02270115  0.03573449]\n",
      "  [ 0.00115754 -0.01358572  0.04611523 -0.04560394]\n",
      "  [-0.04805122 -0.04611958 -0.00368042 -0.02210575]\n",
      "  [-0.00956595 -0.0129882  -0.01961517  0.02310673]\n",
      "  [-0.01906455 -0.02397597 -0.0219898   0.01834418]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326771b",
   "metadata": {},
   "source": [
    "Outout에서의 shape(3, 5, 4)\n",
    "= (입력 문장의 개수, 입력문장의 최대 길이, 워드 벡터의 차원수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "339c0525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e1881f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "319bc176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb841b",
   "metadata": {},
   "source": [
    "1-D CNN과 RNN을 섞어 쓸 수도 있다. \n",
    "FFN(Feed Forward Newtwork)만으로 구성할 수도 있다. \n",
    "Transformer layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a32ead",
   "metadata": {},
   "source": [
    "# IMDB 영화리뷰 감성분석 (1) IMDB 데이터셋 분석\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c93fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5b29d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db321bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7866e640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80f54e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab20770",
   "metadata": {},
   "source": [
    "pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.\n",
    "문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다. \n",
    "이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89107d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e1c96d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a863c",
   "metadata": {},
   "source": [
    "Q9. RNN 활용 시 pad_sequences의 padding 방식은 'post'와 'pre' 중 어느 것이 유리할까요? \n",
    "그 이유는 무엇일까요?\n",
    "\n",
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 됩니다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적입니다. 따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4c4c3",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8693ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n",
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df7dffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be09cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ce1b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   13  235 5396    0]\n",
      " [   1   13 1900 6803    0]\n",
      " [   1  150   13  235  654]]\n",
      "tf.Tensor(\n",
      "[[[ 0.02666638  0.02103719 -0.02463411 -0.04781009]\n",
      "  [-0.0409029  -0.01939142  0.00429207  0.01914128]\n",
      "  [ 0.03337837  0.01384049 -0.02245493 -0.02187165]\n",
      "  [-0.01379798  0.02138275 -0.04089691 -0.03048711]\n",
      "  [-0.04500675  0.00283849  0.01205711 -0.04424006]]\n",
      "\n",
      " [[ 0.02666638  0.02103719 -0.02463411 -0.04781009]\n",
      "  [-0.0409029  -0.01939142  0.00429207  0.01914128]\n",
      "  [-0.03922782  0.0196254  -0.0036276  -0.03954406]\n",
      "  [ 0.00441999  0.02710173  0.02851266 -0.04721003]\n",
      "  [-0.04500675  0.00283849  0.01205711 -0.04424006]]\n",
      "\n",
      " [[ 0.02666638  0.02103719 -0.02463411 -0.04781009]\n",
      "  [ 0.02832141  0.03577873  0.04136609 -0.04015522]\n",
      "  [-0.0409029  -0.01939142  0.00429207  0.01914128]\n",
      "  [ 0.03337837  0.01384049 -0.02245493 -0.02187165]\n",
      "  [-0.02929403  0.04192949  0.03657709 -0.00633306]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3962/311634172.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# raw_inputs의 문장의 길이를 PAD를 이용하여 동일하게 만들기\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "\n",
    "# Embedding\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d557d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "# raw_inputs의 문장의 길이를 PAD를 이용하여 동일하게 만들기\n",
    "\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "\n",
    "# Embedding\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5dac59",
   "metadata": {},
   "source": [
    "# 딥러닝 모델 설계와 훈련\n",
    "## RNN 모델을 직접 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "865515cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00054538  0.0374161   0.04394401 -0.00261586]\n",
      "  [ 0.03477428 -0.00557065 -0.02278692  0.03299156]\n",
      "  [ 0.0493491   0.02939073 -0.01579206  0.01641895]\n",
      "  [-0.03033551  0.03495378  0.01021139 -0.00638813]\n",
      "  [-0.03000807  0.04632372  0.01013935 -0.02789087]]\n",
      "\n",
      " [[ 0.00054538  0.0374161   0.04394401 -0.00261586]\n",
      "  [ 0.03477428 -0.00557065 -0.02278692  0.03299156]\n",
      "  [-0.04570956  0.02845628  0.03783857  0.04381308]\n",
      "  [-0.04578506  0.04788288 -0.0158416   0.02870668]\n",
      "  [-0.03000807  0.04632372  0.01013935 -0.02789087]]\n",
      "\n",
      " [[ 0.00054538  0.0374161   0.04394401 -0.00261586]\n",
      "  [ 0.04225749 -0.02801248  0.03578106 -0.01657528]\n",
      "  [ 0.03477428 -0.00557065 -0.02278692  0.03299156]\n",
      "  [ 0.0493491   0.02939073 -0.01579206  0.01641895]\n",
      "  [ 0.04820801  0.00397642 -0.04753726 -0.04543849]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4  \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "\n",
    "\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "040c6afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77ff8fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82229611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e94f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1209f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "the\n",
      "1\n",
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))\n",
    "\n",
    "# 데이터 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "\n",
    "# word_index 가져오기\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력 \n",
    "print(word_to_index['the'])  # 1 이 출력\n",
    "\n",
    "# decoding\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b829bad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b0f233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수정\n",
    "\n",
    "word_to_index = {k:(v+3) for  k,v in word_to_index.items()}\n",
    "word_to_index [\"<PAD>\"] = 0\n",
    "word_to_index [\"<BOS>\"] = 1\n",
    "word_to_index [\"<UNK>\"] = 2\n",
    "word_to_index [\"<UNUSED>\"] = 3\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e431c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f73e2b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c197831",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e57fed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5521 - val_loss: 0.6864 - val_accuracy: 0.6859\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6790 - accuracy: 0.7065 - val_loss: 0.6705 - val_accuracy: 0.7591\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6542 - accuracy: 0.7900 - val_loss: 0.6402 - val_accuracy: 0.7864\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6120 - accuracy: 0.8197 - val_loss: 0.5945 - val_accuracy: 0.8036\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.8413 - val_loss: 0.5390 - val_accuracy: 0.8176\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.8569 - val_loss: 0.4828 - val_accuracy: 0.8230\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8676 - val_loss: 0.4368 - val_accuracy: 0.8318\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8781 - val_loss: 0.4020 - val_accuracy: 0.8393\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8894 - val_loss: 0.3774 - val_accuracy: 0.8445\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2956 - accuracy: 0.8985 - val_loss: 0.3608 - val_accuracy: 0.8470\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2679 - accuracy: 0.9073 - val_loss: 0.3492 - val_accuracy: 0.8510\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2446 - accuracy: 0.9169 - val_loss: 0.3415 - val_accuracy: 0.8535\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2241 - accuracy: 0.9236 - val_loss: 0.3364 - val_accuracy: 0.8549\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2061 - accuracy: 0.9297 - val_loss: 0.3333 - val_accuracy: 0.8560\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1901 - accuracy: 0.9363 - val_loss: 0.3321 - val_accuracy: 0.8567\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9440 - val_loss: 0.3320 - val_accuracy: 0.8562\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1623 - accuracy: 0.9493 - val_loss: 0.3330 - val_accuracy: 0.8555\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1499 - accuracy: 0.9544 - val_loss: 0.3344 - val_accuracy: 0.8568\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9594 - val_loss: 0.3369 - val_accuracy: 0.8563\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9632 - val_loss: 0.3404 - val_accuracy: 0.8560\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 모델 학습\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "627a23d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3593 - accuracy: 0.8464\n",
      "[0.35932159423828125, 0.8464400172233582]\n"
     ]
    }
   ],
   "source": [
    "#모델 평가하기\n",
    "\n",
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14293ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ccccb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af90c887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f85b9",
   "metadata": {},
   "source": [
    "# word2Vec의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27e9aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4beaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "107da176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import gensim\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baf8cfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02105616, -0.04415524, -0.02501934, -0.02048003, -0.01727389,\n",
       "       -0.03413421, -0.0129603 , -0.01981093, -0.01478659, -0.01935776,\n",
       "       -0.03074113, -0.03293924, -0.02583587, -0.01714275, -0.04273629,\n",
       "       -0.02004693], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors \n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d369337",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mr', 0.98471599817276),\n",
       " ('kill', 0.9839111566543579),\n",
       " ('stereotypes', 0.9818060398101807),\n",
       " ('surprisingly', 0.9813902378082275),\n",
       " ('spell', 0.9805036187171936),\n",
       " ('sit', 0.9776443243026733),\n",
       " ('interested', 0.9775366187095642),\n",
       " ('huge', 0.9759951829910278),\n",
       " ('has', 0.9755967855453491),\n",
       " ('nasty', 0.9735386371612549)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89dc29a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'6 ')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/3146946651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword2vec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'computer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#300차원의 워드 벡터입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1963\u001b[0m             \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0;31m# jump to the next member, if there is one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_gzip_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36m_read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'\\037\\213'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not a gzipped file (%r)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         (method, flag,\n",
      "\u001b[0;31mBadGzipFile\u001b[0m: Not a gzipped file (b'6 ')"
     ]
    }
   ],
   "source": [
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = w2v.load_word2vec_format(word2vec_path,binary = True,limit = 1000000)\n",
    "vector = word2vec['computer']\n",
    "#300차원의 워드 벡터입니다.\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f147a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/4063403497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"love\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13899cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'type' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/2338076999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'type' is not iterable"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec as word2vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 300\n",
    "embedding_matrix = np.random.rand(vocab_size,word_vector_dim)\n",
    "\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "121bc4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12996729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 88ms/step - loss: 0.6948 - accuracy: 0.5035 - val_loss: 0.6933 - val_accuracy: 0.4947\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6932 - val_accuracy: 0.4947\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.6930 - accuracy: 0.5051 - val_loss: 0.6931 - val_accuracy: 0.5099\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6927 - accuracy: 0.5229 - val_loss: 0.6933 - val_accuracy: 0.4947\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6924 - accuracy: 0.5200 - val_loss: 0.6935 - val_accuracy: 0.4947\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6919 - accuracy: 0.5311 - val_loss: 0.6930 - val_accuracy: 0.4963\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6909 - accuracy: 0.5331 - val_loss: 0.6930 - val_accuracy: 0.4949\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6897 - accuracy: 0.5386 - val_loss: 0.6942 - val_accuracy: 0.4947\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6864 - accuracy: 0.6027 - val_loss: 0.6938 - val_accuracy: 0.4947\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6813 - accuracy: 0.6625 - val_loss: 0.6920 - val_accuracy: 0.4947\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6719 - accuracy: 0.6265 - val_loss: 0.6861 - val_accuracy: 0.4972\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6554 - accuracy: 0.6237 - val_loss: 0.6885 - val_accuracy: 0.5352\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6321 - accuracy: 0.6916 - val_loss: 0.6707 - val_accuracy: 0.5157\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.5553 - accuracy: 0.8579 - val_loss: 0.6076 - val_accuracy: 0.7173\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.4587 - accuracy: 0.8574 - val_loss: 0.5698 - val_accuracy: 0.6965\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 82ms/step - loss: 0.3451 - accuracy: 0.9179 - val_loss: 0.4987 - val_accuracy: 0.7710\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.2561 - accuracy: 0.9499 - val_loss: 0.4752 - val_accuracy: 0.7848\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.2004 - accuracy: 0.9619 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1678 - accuracy: 0.9648 - val_loss: 0.5347 - val_accuracy: 0.7366\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3133ded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5294 - accuracy: 0.7402\n",
      "[0.5294318199157715, 0.7401999831199646]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1f338",
   "metadata": {},
   "source": [
    "# Project 네이버 영화 리뷰 감정 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a2add7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e76f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=19000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "    test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "748e481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3962/325033547.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_3962/325033547.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_3962/325033547.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_3962/325033547.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70c8b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 67, 895, 33, 214, 15, 28, 699], [977, 481, 491, 636, 4, 110, 1554, 48, 866, 949, 11, 38, 364], [19, 192, 3]]\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(X_train[:3])\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2\n",
    "word_to_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d472b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이의 평균 : 13.718233430088207\n",
      "문장 길이의 최대 : 83\n",
      "문장 길이의 표준편차 : 11.469848902034261\n",
      "전체 문장의 0.9340019146202243%가 maxlen값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "#전체 데이터에 적용시킬 수 있을만한 maxlen값을 찾도록 하겠습니다.\n",
    "total_data_text = list(X_train)+list(X_test)\n",
    "#문장의 길이를 리스트로 저장한뒤 numpy함수를 사용하기 위해 numpy 리스트로 변환합니다.\n",
    "num_tokens = [len(token) for token in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print(\"문장 길이의 평균 :\", np.mean(num_tokens))\n",
    "print(\"문장 길이의 최대 :\", np.max(num_tokens))\n",
    "print(\"문장 길이의 표준편차 :\", np.std(num_tokens))\n",
    "#임시로 maxlen을 평균 + 2 * 표준편차라고 한다면,\n",
    "max_tokens = np.mean(num_tokens)+2*np.std(num_tokens)\n",
    "#실수형 데이터를 정수로 바꿔줍니다.\n",
    "maxlen = int(max_tokens)\n",
    "print(\"전체 문장의 {}%가 maxlen값 이내에 포함됩니다.\".format(np.sum(num_tokens<max_tokens)/len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36df1e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  27  67 895  33 214  15  28 699]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 788 128]\n",
      "(146182, 36)\n",
      "(49157, 36)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                       maxlen=maxlen)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                       maxlen=maxlen)\n",
    "print(X_train[0])\n",
    "print(X_test[0])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d35fdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:40000]\n",
    "y_val = y_train[:40000]\n",
    "X_train = X_train[40000:]\n",
    "y_train = y_train[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50cc440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 19000\n",
    "word_vector_dim = 32\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4059788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = tf.keras.Sequential()\n",
    "first_model.add(tf.keras.layers.Embedding(vocab_size,word_vector_dim,input_shape=(None,)))\n",
    "first_model.add(tf.keras.layers.LSTM(128))\n",
    "first_model.add(tf.keras.layers.Dense(8,activation='relu'))\n",
    "first_model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "second_model = tf.keras.Sequential()\n",
    "second_model.add(tf.keras.layers.Embedding(vocab_size,word_vector_dim,input_shape=(None,)))\n",
    "second_model.add(tf.keras.layers.LSTM(128))\n",
    "second_model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "third_model = tf.keras.Sequential()\n",
    "third_model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "third_model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "third_model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "third_model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "third_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ccd31494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "208/208 [==============================] - 4s 11ms/step - loss: 0.4646 - accuracy: 0.7751 - val_loss: 0.3603 - val_accuracy: 0.8421\n",
      "Epoch 2/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.3339 - accuracy: 0.8548 - val_loss: 0.3561 - val_accuracy: 0.8432\n",
      "Epoch 3/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.3019 - accuracy: 0.8729 - val_loss: 0.3589 - val_accuracy: 0.8460\n",
      "Epoch 4/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.2760 - accuracy: 0.8852 - val_loss: 0.3700 - val_accuracy: 0.8416\n",
      "Epoch 5/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.2538 - accuracy: 0.8965 - val_loss: 0.3866 - val_accuracy: 0.8386\n",
      "Epoch 6/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.2343 - accuracy: 0.9055 - val_loss: 0.4095 - val_accuracy: 0.8402\n",
      "Epoch 1/6\n",
      "208/208 [==============================] - 3s 10ms/step - loss: 0.4740 - accuracy: 0.7715 - val_loss: 0.3668 - val_accuracy: 0.8399\n",
      "Epoch 2/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.3388 - accuracy: 0.8544 - val_loss: 0.3552 - val_accuracy: 0.8438\n",
      "Epoch 3/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.3079 - accuracy: 0.8705 - val_loss: 0.3573 - val_accuracy: 0.8437\n",
      "Epoch 4/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.2855 - accuracy: 0.8804 - val_loss: 0.3585 - val_accuracy: 0.8456\n",
      "Epoch 5/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.2626 - accuracy: 0.8918 - val_loss: 0.3790 - val_accuracy: 0.8428\n",
      "Epoch 6/6\n",
      "208/208 [==============================] - 2s 9ms/step - loss: 0.2395 - accuracy: 0.9025 - val_loss: 0.3810 - val_accuracy: 0.8438\n",
      "Epoch 1/6\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.6030 - accuracy: 0.7334 - val_loss: 0.4717 - val_accuracy: 0.8024\n",
      "Epoch 2/6\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.8295 - val_loss: 0.3877 - val_accuracy: 0.8232\n",
      "Epoch 3/6\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8568 - val_loss: 0.3780 - val_accuracy: 0.8290\n",
      "Epoch 4/6\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.2976 - accuracy: 0.8754 - val_loss: 0.3805 - val_accuracy: 0.8308\n",
      "Epoch 5/6\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.8907 - val_loss: 0.3893 - val_accuracy: 0.8303\n",
      "Epoch 6/6\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 0.2409 - accuracy: 0.9036 - val_loss: 0.4029 - val_accuracy: 0.8290\n"
     ]
    }
   ],
   "source": [
    "first_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "first_history = first_model.fit(X_train,\n",
    "                           y_train,\n",
    "                           epochs=epochs,\n",
    "                           batch_size = 512,\n",
    "                           validation_data=(X_val,y_val),\n",
    "                           verbose = 1)\n",
    "second_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "second_history = second_model.fit(X_train,\n",
    "                           y_train,\n",
    "                           epochs=epochs,\n",
    "                           batch_size = 512,\n",
    "                           validation_data=(X_val,y_val),\n",
    "                           verbose = 1)\n",
    "\n",
    "third_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "third_history = third_model.fit(X_train,\n",
    "                           y_train,\n",
    "                           epochs=epochs,\n",
    "                           batch_size = 512,\n",
    "                           validation_data=(X_val,y_val),\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f06deafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.4189 - accuracy: 0.8338\n",
      "모델의 정확도는 83% 입니다.\n",
      "1537/1537 - 3s - loss: 0.3903 - accuracy: 0.8364\n",
      "모델의 정확도는 83% 입니다.\n",
      "1537/1537 - 2s - loss: 0.4130 - accuracy: 0.8248\n",
      "모델의 정확도는 82% 입니다.\n"
     ]
    }
   ],
   "source": [
    "model_loss,model_acc = first_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"모델의 정확도는 {}% 입니다.\".format(int(model_acc*100)))\n",
    "model_loss,model_acc = second_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"모델의 정확도는 {}% 입니다.\".format(int(model_acc*100)))\n",
    "model_loss,model_acc = third_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"모델의 정확도는 {}% 입니다.\".format(int(model_acc*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4c75a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = second_history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6a08768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAovUlEQVR4nO3de5xVdb3/8debERiGm9xUZETwhKIe5DZhYpqmdkhNj6YniEqyn6SlnfhVpidLjsX5ncrSY6knvKcUkac4VJil6dHKkwyKJCiJhjpeElGR+/Xz+2OtGTabNTObcfbsmdnv5+OxH3ut77rsz9oD67O/3+9a66uIwMzMLF+XUgdgZmbtkxOEmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCCuYpHskndfa65aSpFWSTi7CfkPSu9Lp/5T01ULWbcHnTJX0m5bGadYU+T6Izk3S+pzZKmALsCOd/3REzGn7qNoPSauA/xMR97XyfgMYERErW2tdScOAvwJdI2J7qwRq1oR9Sh2AFVdE9KqfbupkKGkfn3SsvfC/x/bBTUxlStIJkuokfVnSq8BtkvpJ+qWk1ZLeTKerc7Z5UNL/SaenSfq9pKvTdf8q6YMtXHe4pIckrZN0n6TrJd3VSNyFxPh1SX9I9/cbSQNzln9c0vOS1kj6ShPfz9GSXpVUkVN2lqSl6fQESY9IekvSK5K+L6lbI/u6XdI3cua/lG7zsqTz89Y9TdLjkt6W9KKkmTmLH0rf35K0XtIx9d9tzvYTJS2StDZ9n1jod7OX33N/Sbelx/CmpPk5y86UtCQ9hmclTUrLd2vOkzSz/u8saVja1PYpSS8Av0vLf5r+Hdam/0aOzNm+h6TvpH/Ptem/sR6SfiXpkrzjWSrprKxjtcY5QZS3A4D+wMHAdJJ/D7el80OBTcD3m9j+aGAFMBD4FnCLJLVg3R8BjwIDgJnAx5v4zEJi/CjwSWA/oBvwRQBJRwA3pvs/MP28ajJExJ+ADcD78/b7o3R6BzAjPZ5jgJOAzzQRN2kMk9J4TgFGAPn9HxuATwD7AqcBF0n6x3TZ8en7vhHRKyIeydt3f+BXwHXpsX0X+JWkAXnHsMd3k6G57/lOkibLI9N9XZPGMAH4IfCl9BiOB1Y18hlZ3gccDvxDOn8Pyfe0H/AYkNskejUwHphI8u/4UmAncAfwsfqVJI0GhpB8N7Y3IsKvMnmR/Ec9OZ0+AdgKVDax/hjgzZz5B0maqACmAStzllUBARywN+uSnHy2A1U5y+8C7irwmLJivCJn/jPAr9PprwFzc5b1TL+DkxvZ9zeAW9Pp3iQn74MbWffzwM9z5gN4Vzp9O/CNdPpW4N9z1js0d92M/V4LXJNOD0vX3Sdn+TTg9+n0x4FH87Z/BJjW3HezN98zMJjkRNwvY70f1Mfb1L+/dH5m/d8559gOaSKGfdN1+pIksE3A6Iz1KoE3Sfp1IEkkNxTj/1Rnf7kGUd5WR8Tm+hlJVZJ+kFbZ3yZp0tg3t5klz6v1ExGxMZ3stZfrHgi8kVMG8GJjARcY46s50xtzYjowd98RsQFY09hnkdQWzpbUHTgbeCwink/jODRtdnk1jePfSGoTzdktBuD5vOM7WtIDadPOWuDCAvdbv+/n88qeJ/n1XK+x72Y3zXzPB5H8zd7M2PQg4NkC483S8N1IqpD072kz1dvsqokMTF+VWZ+V/pv+CfAxSV2AKSQ1HttLThDlLf8Sti8AhwFHR0QfdjVpNNZs1BpeAfpLqsopO6iJ9d9JjK/k7jv9zAGNrRwRy0lOsB9k9+YlSJqqnib5ldoH+JeWxEBSg8r1I2ABcFBE9AX+M2e/zV1y+DJJk1CuocBLBcSVr6nv+UWSv9m+Gdu9CPxdI/vcQFJ7rHdAxjq5x/hR4EySZri+JLWM+hheBzY38Vl3AFNJmv42Rl5znBXGCcJy9Saptr+VtmdfWewPTH+R1wIzJXWTdAzwoSLFeDdwuqT3ph3KV9H8/4EfAf9McoL8aV4cbwPrJY0ELiowhnnANElHpAkqP/7eJL/ON6ft+R/NWbaapGnnkEb2vRA4VNJHJe0j6SPAEcAvC4wtP47M7zkiXiHpG7gh7czuKqk+gdwCfFLSSZK6SBqSfj8AS4DJ6fo1wDkFxLCFpJZXRVJLq49hJ0lz3XclHZjWNo5Ja3ukCWEn8B1ce2gxJwjLdS3Qg+TX2f8Cv26jz51K0tG7hqTd/yckJ4Ys19LCGCNiGfBZkpP+KyTt1HXNbPZjko7T30XE6znlXyQ5ea8DbkpjLiSGe9Jj+B2wMn3P9RngKknrSPpM5uVsuxGYBfxBydVT78nb9xrgdJJf/2tIOm1Pz4u7UNfS9Pf8cWAbSS3qNZI+GCLiUZJO8GuAtcD/sKtW81WSX/xvAv/K7jWyLD8kqcG9BCxP48j1ReDPwCLgDeCb7H5O+yEwiqRPy1rAN8pZuyPpJ8DTEVH0Gox1XpI+AUyPiPeWOpaOyjUIKzlJ75b0d2mTxCSSduf5JQ7LOrC0+e4zwOxSx9KROUFYe3AAySWY60mu4b8oIh4vaUTWYUn6B5L+mr/RfDOWNcFNTGZmlsk1CDMzy9RpHtY3cODAGDZsWKnDMDPrUBYvXvx6RAzKWtZpEsSwYcOora0tdRhmZh2KpPy77xu4icnMzDI5QZiZWSYnCDMzy9Rp+iCybNu2jbq6OjZv3tz8ylYSlZWVVFdX07Vr11KHYmZ5OnWCqKuro3fv3gwbNozGx7GxUokI1qxZQ11dHcOHDy91OGaWp1M3MW3evJkBAwY4ObRTkhgwYIBreGYtNGcODBsGXbok73PmNLfF3unUNQjAyaGd89/HrGXmzIHp02FjOtTW888n8wBTp7bOZ3TqGoSZWWf1la/sSg71Nm5MyluLE0QRrVmzhjFjxjBmzBgOOOAAhgwZ0jC/devWJretra3lc5/7XLOfMXHixNYK18w6kBde2LvylihqgpA0SdIKSSslXZax/GBJ90taKulBSdU5y86T9Ez6Oq+YcdZr7fa8AQMGsGTJEpYsWcKFF17IjBkzGua7devG9u3bG922pqaG6667rtnP+OMf//jOgjSzDmlo/mC1zZS3RNESRDq4+fUk4/keAUyRdETealcDP4yIo0iGf/x/6bb1QxweDUwArpTUr1ixwq72vOefh4hd7Xmt3ekzbdo0LrzwQo4++mguvfRSHn30UY455hjGjh3LxIkTWbFiBQAPPvggp59+OgAzZ87k/PPP54QTTuCQQw7ZLXH06tWrYf0TTjiBc845h5EjRzJ16lTqn9S7cOFCRo4cyfjx4/nc5z7XsN9cq1at4rjjjmPcuHGMGzdut8TzzW9+k1GjRjF69GguuyzJ8ytXruTkk09m9OjRjBs3jmeffSfj1JvZ3po1C6qqdi+rqkrKW01EFOVFMoTkvTnzlwOX562zjGRwdkgGIn87nZ4C/CBnvR8AU5r6vPHjx0e+5cuX71HWmIMPjkhSw+6vgw8ueBdNuvLKK+Pb3/52nHfeeXHaaafF9u3bIyJi7dq1sW3btoiI+O1vfxtnn312REQ88MADcdpppzVse8wxx8TmzZtj9erV0b9//9i6dWtERPTs2bNh/T59+sSLL74YO3bsiPe85z3x8MMPx6ZNm6K6ujqee+65iIiYPHlyw35zbdiwITZt2hQREX/5y1+i/vtcuHBhHHPMMbFhw4aIiFizZk1EREyYMCF+9rOfRUTEpk2bGpa3xN78ncxsl7vuSs5RUvJ+1117vw+gNho5rxbzKqYhwIs583UkNYJcTwBnA/8BnAX0ljSgkW2H5H+ApOnAdICh77Be1RbtefXOPfdcKioqAFi7di3nnXcezzzzDJLYtm1b5jannXYa3bt3p3v37uy333787W9/o7q6erd1JkyY0FA2ZswYVq1aRa9evTjkkEMa7jOYMmUKs2fvOcjWtm3buPjii1myZAkVFRX85S9/AeC+++7jk5/8JFXpT5X+/fuzbt06XnrpJc466ywgudnNzNre1Kmtd8VSllJ3Un8ReJ+kx0kGhn8J2FHoxhExOyJqIqJm0KDMp9UWrC3a8+r17NmzYfqrX/0qJ554Ik8++SS/+MUvGr0noHv37g3TFRUVmf0XhazTmGuuuYb999+fJ554gtra2mY70c2s8ytmgngJOChnvjotaxARL0fE2RExFvhKWvZWIdu2tjZpz8uwdu1ahgxJKke33357q+//sMMO47nnnmPVqlUA/OQnP2k0jsGDB9OlSxfuvPNOduxI8vQpp5zCbbfdxsb0ero33niD3r17U11dzfz58wHYsmVLw3Iz6zyKmSAWASMkDZfUDZgMLMhdQdJASfUxXA7cmk7fC3xAUr+0c/oDaVnRTJ0Ks2fDwQeDlLzPnl3c6hvApZdeyuWXX87YsWP36hd/oXr06MENN9zApEmTGD9+PL1796Zv3757rPeZz3yGO+64g9GjR/P000831HImTZrEGWecQU1NDWPGjOHqq68G4M477+S6667jqKOOYuLEibz66qutHruZlVZRx6SWdCpwLVAB3BoRsyRdRdIpskDSOSRXLgXwEPDZiNiSbns+8C/prmZFxG1NfVZNTU3kDxj01FNPcfjhh7fmIXVI69evp1evXkQEn/3sZxkxYgQzZswodVgN/HcyKx1JiyOiJmtZUR+1ERELgYV5ZV/Lmb4buLuRbW9lV43C3oGbbrqJO+64g61btzJ27Fg+/elPlzokM+sAOv2zmAxmzJjRrmoMZtYxlPoqJjMza6ecIMzMLJMThJl1CsUeG6EcuQ/CzDq8thgboRy5BlFEJ554Ivfeu/vtG9deey0XXXRRo9uccMIJ1F+ue+qpp/LWW2/tsc7MmTMb7kdozPz581m+fHnD/Ne+9jXuu+++vYjerONoi7ERypETRBFNmTKFuXPn7lY2d+5cpkyZUtD2CxcuZN99923RZ+cniKuuuoqTTz65Rfsya+/a8llq5cQJoojOOeccfvWrXzU812jVqlW8/PLLHHfccVx00UXU1NRw5JFHcuWVV2ZuP2zYMF5//XUAZs2axaGHHsp73/vehkeCQ3KPw7vf/W5Gjx7Nhz/8YTZu3Mgf//hHFixYwJe+9CXGjBnDs88+y7Rp07j77uSWk/vvv5+xY8cyatQozj//fLZs2dLweVdeeSXjxo1j1KhRPP3003vE5MeCW3vUls9SKydl0wfx+c/DkiWtu88xY+Daaxtf3r9/fyZMmMA999zDmWeeydy5c/mnf/onJDFr1iz69+/Pjh07OOmkk1i6dClHHXVU5n4WL17M3LlzWbJkCdu3b2fcuHGMHz8egLPPPpsLLrgAgCuuuIJbbrmFSy65hDPOOIPTTz+dc845Z7d9bd68mWnTpnH//fdz6KGH8olPfIIbb7yRz3/+8wAMHDiQxx57jBtuuIGrr76am2++ebft99tvP377299SWVnJM888w5QpU6itreWee+7hv//7v/nTn/5EVVUVb7zxBgBTp07lsssu46yzzmLz5s3s3Llz779os2bMmrV7HwS0zbPUOjvXIIost5kpt3lp3rx5jBs3jrFjx7Js2bLdmoPyPfzww5x11llUVVXRp08fzjjjjIZlTz75JMcddxyjRo1izpw5LFu2rMl4VqxYwfDhwzn00EMBOO+883jooYcalp999tkAjB8/vuEBf7m2bdvGBRdcwKhRozj33HMb4i70seBV+U9ENGsFpXqWWmdXNjWIpn7pF9OZZ57JjBkzeOyxx9i4cSPjx4/nr3/9K1dffTWLFi2iX79+TJs2rdHHfDdn2rRpzJ8/n9GjR3P77bfz4IMPvqN46x8Z3tjjwnMfC75z506PBWHtRrHHRihHrkEUWa9evTjxxBM5//zzG2oPb7/9Nj179qRv37787W9/45577mlyH8cffzzz589n06ZNrFu3jl/84hcNy9atW8fgwYPZtm0bc3Iu/O7duzfr1q3bY1+HHXYYq1atYuXKlUDyVNb3ve99BR+PHwtuVj6cINrAlClTeOKJJxoSxOjRoxk7diwjR47kox/9KMcee2yT248bN46PfOQjjB49mg9+8IO8+93vblj29a9/naOPPppjjz2WkSNHNpRPnjyZb3/724wdO3a3juHKykpuu+02zj33XEaNGkWXLl248MILCz4WPxbcrHwU9XHfbcmP++64/HcyK52mHvftGoSZmWVygjAzs0ydPkF0lia0zsp/H7P2q1MniMrKStasWeOTUDsVEaxZs8aXypq1U536Pojq6mrq6upYvXp1qUOxRlRWVlJdXV3qMMwsQ6dOEF27dmX48OGlDsPMrEPq1E1MZmbWckVNEJImSVohaaWkyzKWD5X0gKTHJS2VdGpa3lXSHZL+LOkpSZcXM06zzsajq1lrKFoTk6QK4HrgFKAOWCRpQUTkPpXuCmBeRNwo6QhgITAMOBfoHhGjJFUByyX9OCJWFStes87Co6tZaylmDWICsDIinouIrcBc4My8dQLok073BV7OKe8paR+gB7AVeLuIsZp1Gh5dzVpLMRPEEODFnPm6tCzXTOBjkupIag+XpOV3AxuAV4AXgKsj4o38D5A0XVKtpFpfqWSW8Ohq1lpK3Uk9Bbg9IqqBU4E7JXUhqX3sAA4EhgNfkHRI/sYRMTsiaiKiZtCgQW0Zt1m75dHVrLUUM0G8BByUM1+dluX6FDAPICIeASqBgcBHgV9HxLaIeA34A5D5MCkz292sWcloark8upq1RDETxCJghKThkroBk4EFeeu8AJwEIOlwkgSxOi1/f1reE3gPsOcAyWa2B4+uZq2laFcxRcR2SRcD9wIVwK0RsUzSVUBtRCwAvgDcJGkGScf0tIgISdcDt0laBgi4LSKWFitWs87Go6tZa+jU40GYmVnTPB6EmZntNScIMzPL5ARhZmaZnCDMzCyTE4SZmWVygrBOz082NWuZTj1gkJmfbGrWcq5BWKfmJ5uatZwThHVqfrKpWcs5QVin5iebmrWcE4R1an6yqVnLOUFYp+Ynm5q1nK9isk7PTzY1axnXIMzMLJMThJmZZXKCMDOzTE4QZmaWyQnCzMwyOUGYmVkmJwgzM8vkBGFmZpmKmiAkTZK0QtJKSZdlLB8q6QFJj0taKunUnGVHSXpE0jJJf5ZUWcxYzcxsd0W7k1pSBXA9cApQByyStCAiluesdgUwLyJulHQEsBAYJmkf4C7g4xHxhKQBwLZixWpmZnsqZg1iArAyIp6LiK3AXODMvHUC6JNO9wVeTqc/ACyNiCcAImJNROwoYqxmZpanmAliCPBiznxdWpZrJvAxSXUktYdL0vJDgZB0r6THJF2a9QGSpkuqlVS7evXq1o3ezKzMlbqTegpwe0RUA6cCd0rqQtL09V5gavp+lqST8jeOiNkRURMRNYMGDWrLuM3MOr1iJoiXgINy5qvTslyfAuYBRMQjQCUwkKS28VBEvB4RG0lqF+OKGKuZmeUpZoJYBIyQNFxSN2AysCBvnReAkwAkHU6SIFYD9wKjJFWlHdbvA5ZjZmZtpmhXMUXEdkkXk5zsK4BbI2KZpKuA2ohYAHwBuEnSDJIO62kREcCbkr5LkmQCWBgRvypWrGZmticl5+OOr6amJmpra0sdhplZhyJpcUTUZC0rdSe1tbE5c2DYMOjSJXmfM6fUEZlZe+UhR8vInDkwfTps3JjMP/98Mg8ektPM9uQaRBn5yld2JYd6Gzcm5WZm+ZwgysgLL+xduZmVNyeIMjJ06N6Vm1l5c4IoI7NmQVXV7mVVVUm5mVk+J4gyMnUqzJ4NBx8MUvI+e7Y7qM0sm69iKjNTpzohmFlhXIMwM7NMzSYISR9Kn7BqZmZlpJAT/0eAZyR9S9LIYgdkZmbtQ7MJIiI+BowFngVuT8eJni6pd9GjMzOzkimo6Sgi3gbuJhk2dDBwFvCYpEua3NDMzDqsQvogzpD0c+BBoCswISI+CIwmeVy3mZl1QoVc5vph4JqIeCi3MCI2SvpUccIyM7NSKyRBzAReqZ+R1APYPyJWRcT9xQrMzHaJgK1bYf36Xa9163afz3rt3An9+kH//rvec6f79YPevZMbJ83yFZIgfgpMzJnfkZa9uygRmXVwEbBpU/Mn70JO8Lmv7dsLj6FnT+jVK5l+880kuTSmomLPpJGfSLKW9+sH3bq9s+/K2rdCEsQ+EdHwzysitqZjTJt1eDt3woYNe3eiLuQEX+hAjVJyIs9/7bcfHHJI9rLmXlVVyUm/Xn3CeuONJFnkvmdNv/YarFiRzL/1VtPx9+zZeAJpKsH06eNaS0dQSIJYLemMdAxpJJ0JvF7csKylduyA1avhlVfg1VeT99zp+vfXX09OHNKu/6j108Uqa6vPaawsPxmsW7fn+BhNqahImmPyT8hDhuxZlrVe1qtHj+KfKKUkaVRVQXX13m27YwesXdt4UskvW7EieV+zBrZsaXy/FRVJomhJraV793f2fbxTO3YkNbLGXlu2NL28NV75n3HqqfC977X+sRaSIC4E5kj6PiDgReATrR+KNWXjxj1P8lkn/tdeS06E+fr2hcGD4YAD4OijYeDAZNjR+l+6Ebte+fOFlrV0u7baV5cuMGhQYSfurBN8t27l96u3vvmpf/+933bTpqZrLLlla9bAM8/sqrU0VQOrqmq61tK9e3FP3ln/v1pD9+7Jv7HmXpWVSQ0st2xkkW5hbjZBRMSzwHsk9Urn1xcnlPITkfzHKOTE//bbe27fpQvsv39y4h88GMaN25UE8t979Gj747Py1qNH8jrwwL3bbufOpNZSSI3ljTdg5cpdZZs27b6vioo9T7CNnYjzT7qt9SrkxF9R0T5/fBT0NFdJpwFHApVKjyIiripgu0nAfwAVwM0R8e95y4cCdwD7putcFhEL85YvB2ZGxNWFxNoebN2anNibO/G/+ips27bn9j177jqxH3UUfOADu5/w66cHDty9rdmsM+jSZVfz0yGH7N22mzcntYTu3aFrV///eKeaTRCS/hOoAk4EbgbOAR4tYLsK4HrgFKAOWCRpQUQsz1ntCmBeRNwo6QhgITAsZ/l3gXsKO5Tiikh+xWf9us8vW7Mmex+DBu06uR9xxJ4n/Pr33n6IiVmLVFYmL2sdhdQgJkbEUZKWRsS/SvoOhZ20JwArI+I5AElzgTNJagT1AuiTTvcFXq5fIOkfgb8CGwr4rBbbsSNpt2+qead+Or/6CskvlfqT+4gRcPzx2c08++2X/KIxM+soCkkQm9P3jZIOBNaQPI+pOUNIOrTr1QFH560zE/hN+kynnsDJAGl/x5dJah9fLOCzWuxPf4Jjj92zvF+/XSf3iROz2/UHD4Z9922fbYdmZu9UIQniF5L2Bb4NPEbyq/+mVvr8KcDtEfEdSccAd0r6e5LEcU1ErFcTZ19J04HpAEOHDm1RAIcdBjfcsHtzz/77u5pqZtZkgkgHCro/It4C/kvSL4HKiFhbwL5fAg7Kma9Oy3J9CpgEEBGPSKoEBpLUNM6R9C2SDuydkjZHxPdzN46I2cBsgJqamgJvTdrdgAFw0UUt2dLMrHNr8mmuEbGTpKO5fn5LgckBYBEwQtLw9M7rycCCvHVeAE4CkHQ4UAmsjojjImJYRAwDrgX+LT85mJlZcRUyHsT9kj6sptp6MkTEduBi4F7gKZKrlZZJukrSGelqXwAukPQE8GNgWkShDykwM7NiUnPnY0nrSDqQt5N0WAuIiOjT5IZtrKamJmpra0sdhplZhyJpcUTUZC0r5E5qX5VvZlaGCrlR7vis8vwBhMzMrHMp5DLXL+VMV5LcALcYeH9RIjIzs3ahkCamD+XOSzqI5MoiMzPrxAq5iilfHXB4awdiZmbtSyF9EN8juXsakoQyhuSOajMz68QK6YPIvXZ0O/DjiPhDkeIxM7N2opAEcTewOSJ2QPIYb0lVEbEXgzWamVlHU9Cd1EDueGQ9gPuKE46ZmbUXhSSIytxhRtPpquKFZGZm7UEhCWKDpHH1M5LGAxlD55iZWWdSSB/E54GfSnqZ5DlMBwAfKWZQZmZWeoXcKLdI0kjgsLRoRURsK25YZmZWas02MUn6LNAzIp6MiCeBXpI+U/zQzMyslArpg7ggHVEOgIh4E7igaBGZmVm7UEiCqMgdLEhSBdCteCGZmVl7UEgn9a+Bn0j6QTr/aeCe4oVkZmbtQSEJ4svAdODCdH4pyZVMZmbWiTXbxBQRO4E/AatIxoJ4P8kY02Zm1ok1WoOQdCgwJX29DvwEICJObJvQzMyslJpqYnoaeBg4PSJWAkia0SZRmZlZyTXVxHQ28ArwgKSbJJ1Ecie1mZmVgUYTRETMj4jJwEjgAZJHbuwn6UZJHyhk55ImSVohaaWkyzKWD5X0gKTHJS2VdGpafoqkxZL+nL57/GszszZWSCf1hoj4UTo2dTXwOMmVTU1K75e4HvggcAQwRdIReatdAcyLiLHAZOCGtPx14EMRMQo4D7izwOMxM7NWsldjUkfEmxExOyJOKmD1CcDKiHguIrYCc4Ez83cJ9Emn+wIvp5/zeES8nJYvA3pI6r43sZqZ2TuzVwliLw0BXsyZr0vLcs0EPiapDlgIXJKxnw8Dj0XElvwFkqZLqpVUu3r16taJ2szMgOImiEJMAW6PiGrgVOBOSQ0xSToS+CbJ3dt7SGszNRFRM2jQoDYJ2MysXBQzQbwEHJQzX52W5foUMA8gIh4BKoGBAJKqgZ8Dn4iIZ4sYp5mZZShmglgEjJA0XFI3kk7oBXnrvACcBCDpcJIEsVrSvsCvgMsi4g9FjNHMzBpRtAQREduBi4F7SR7NMS8ilkm6StIZ6WpfAC6Q9ATwY2BaRES63buAr0lakr72K1asZma2JyXn446vpqYmamtrSx2GmVmHImlxRNRkLSt1J7WZmbVTThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy1TUBCFpkqQVklZKuixj+VBJD0h6XNJSSafmLLs83W6FpH8oZpxmZranfYq1Y0kVwPXAKUAdsEjSgohYnrPaFcC8iLhR0hHAQmBYOj0ZOBI4ELhP0qERsaNY8ZqZ2e6KWYOYAKyMiOciYiswFzgzb50A+qTTfYGX0+kzgbkRsSUi/gqsTPdnZmZtpJgJYgjwYs58XVqWaybwMUl1JLWHS/ZiWyRNl1QrqXb16tWtFbeZmVH6TuopwO0RUQ2cCtwpqeCYImJ2RNRERM2gQYOKFqSZWTkqWh8E8BJwUM58dVqW61PAJICIeERSJTCwwG3NzKyIilmDWASMkDRcUjeSTucFeeu8AJwEIOlwoBJYna43WVJ3ScOBEcCjRYzVzMzyFK0GERHbJV0M3AtUALdGxDJJVwG1EbEA+AJwk6QZJB3W0yIigGWS5gHLge3AZ30Fk5lZ21JyPu74ampqora2ttRhmJl1KJIWR0RN1rJSd1KbmVk75QRhZmaZnCDMzCyTE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0xFTRCSJklaIWmlpMsyll8jaUn6+oukt3KWfUvSMklPSbpOkooZq5mZ7W6fYu1YUgVwPXAKUAcskrQgIpbXrxMRM3LWvwQYm05PBI4FjkoX/x54H/BgseI1M7PdFbMGMQFYGRHPRcRWYC5wZhPrTwF+nE4HUAl0A7oDXYG/FTFWMzPLU8wEMQR4MWe+Li3bg6SDgeHA7wAi4hHgAeCV9HVvRDyVsd10SbWSalevXt3K4ZuZlbf20kk9Gbg7InYASHoXcDhQTZJU3i/puPyNImJ2RNRERM2gQYPaNGAzs86umAniJeCgnPnqtCzLZHY1LwGcBfxvRKyPiPXAPcAxRYnSzMwyFTNBLAJGSBouqRtJEliQv5KkkUA/4JGc4heA90naR1JXkg7qPZqYzMyseIqWICJiO3AxcC/JyX1eRCyTdJWkM3JWnQzMjYjIKbsbeBb4M/AE8ERE/KJYsZqZ2Z60+3m546qpqYna2tpSh2Fm1qFIWhwRNVnL2ksntZmZtTNOEGZmlskJwszMMjlBmJlZprJPEHPmwLBh0KVL8j5nTqkjMjNrH4r2sL6OYM4cmD4dNm5M5p9/PpkHmDq1dHGZmbUHZV2D+MpXdiWHehs3JuVmZuWurBPECy/sXbmZWTkp6wQxdOjelZuZlZOyThCzZkFV1e5lVVVJuZlZuSvrBDF1KsyeDQcfDFLyPnu2O6jNzKDMr2KCJBk4IZiZ7amsaxBmZtY4JwgzM8vkBGFmZpmcIMzMLJMThJmZZeo0I8pJWg08/w52MRB4vZXC6QjK7XjBx1wufMx75+CIGJS1oNMkiHdKUm1jw+51RuV2vOBjLhc+5tbjJiYzM8vkBGFmZpmcIHaZXeoA2li5HS/4mMuFj7mVuA/CzMwyuQZhZmaZnCDMzCxTWScISbdKek3Sk6WOpa1IOkjSA5KWS1om6Z9LHVOxSaqU9KikJ9Jj/tdSx9QWJFVIelzSL0sdS1uRtErSnyUtkVRb6niKTdK+ku6W9LSkpyQd06r7L+c+CEnHA+uBH0bE35c6nrYgaTAwOCIek9QbWAz8Y0QsL3FoRSNJQM+IWC+pK/B74J8j4n9LHFpRSfq/QA3QJyJOL3U8bUHSKqAmIsriRjlJdwAPR8TNkroBVRHxVmvtv6xrEBHxEPBGqeNoSxHxSkQ8lk6vA54ChpQ2quKKxPp0tmv66tS/jCRVA6cBN5c6FisOSX2B44FbACJia2smByjzBFHuJA0DxgJ/KnEoRZc2tywBXgN+GxGd/ZivBS4FdpY4jrYWwG8kLZY0vdTBFNlwYDVwW9qUeLOknq35AU4QZUpSL+C/gM9HxNuljqfYImJHRIwBqoEJkjptk6Kk04HXImJxqWMpgfdGxDjgg8Bn02bkzmofYBxwY0SMBTYAl7XmBzhBlKG0Hf6/gDkR8bNSx9OW0ir4A8CkEodSTMcCZ6Tt8XOB90u6q7QhtY2IeCl9fw34OTChtBEVVR1Ql1MbvpskYbQaJ4gyk3bY3gI8FRHfLXU8bUHSIEn7ptM9gFOAp0saVBFFxOURUR0Rw4DJwO8i4mMlDqvoJPVML7wgbWr5ANBpr1CMiFeBFyUdlhadBLTqxSb7tObOOhpJPwZOAAZKqgOujIhbShtV0R0LfBz4c9omD/AvEbGwdCEV3WDgDkkVJD+K5kVE2Vz6WUb2B36e/AZiH+BHEfHr0oZUdJcAc9IrmJ4DPtmaOy/ry1zNzKxxbmIyM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYdYMSTvSp4PWv1rtblVJw8rpacLWsZT1fRBmBdqUPqbDrKy4BmHWQunYA99Kxx94VNK70vJhkn4naamk+yUNTcv3l/TzdFyKJyRNTHdVIemmdKyK36R3eyPpc+m4HUslzS3RYVoZc4Iwa16PvCamj+QsWxsRo4DvkzxBFeB7wB0RcRQwB7guLb8O+J+IGE3yzJxlafkI4PqIOBJ4C/hwWn4ZMDbdz4XFOTSzxvlOarNmSFofEb0yylcB74+I59IHIL4aEQMkvU4yKNO2tPyViBgoaTVQHRFbcvYxjOTx4yPS+S8DXSPiG5J+TTKg1Xxgfs6YFmZtwjUIs3cmGpneG1typnewq2/wNOB6ktrGIknuM7Q25QRh9s58JOf9kXT6jyRPUQWYCjycTt8PXAQNAxj1bWynkroAB0XEA8CXgb7AHrUYs2LyLxKz5vXIefItwK8jov5S136SlpLUAqakZZeQjPL1JZIRv+qfsPnPwGxJnyKpKVwEvNLIZ1YAd6VJRMB1rT2cpFlz3Adh1kJpH0RNRLxe6ljMisFNTGZmlsk1CDMzy+QahJmZZXKCMDOzTE4QZmaWyQnCzMwyOUGYmVmm/w+KkDLnn8rBuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cac8c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7b6be8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/2233308363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword2vec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/aiffel/sentiment_classification/data/ko.bin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1928\u001b[0m         \"\"\"\n\u001b[1;32m   1929\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \"\"\"\n\u001b[1;32m   1459\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/ko.bin'\n",
    "\n",
    "word2vec = gensim.models.Word2Vec.load(word2vec_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23d5410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.word2vec.Word2Vec'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Word2Vec' has no attribute 'w2v'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/950426245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"하늘\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Word2Vec' has no attribute 'w2v'"
     ]
    }
   ],
   "source": [
    "print(word2vec)\n",
    "word2vec.w2v.most_similar(\"하늘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "980e2311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3962/325033547.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_3962/325033547.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_3962/325033547.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_3962/325033547.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test,word_to_index = load_data(train_data,test_data,25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a73f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2\n",
    "word_to_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57f17a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이의 평균 : 13.718233430088207\n",
      "문장 길이의 최대 : 83\n",
      "문장 길이의 표준편차 : 11.469848902034261\n",
      "전체 문장의 0.9340019146202243%가 maxlen값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_data_text = list(X_train)+list(X_test)\n",
    "\n",
    "num_tokens = [len(token) for token in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print(\"문장 길이의 평균 :\", np.mean(num_tokens))\n",
    "print(\"문장 길이의 최대 :\", np.max(num_tokens))\n",
    "print(\"문장 길이의 표준편차 :\", np.std(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens)+2*np.std(num_tokens)\n",
    "\n",
    "maxlen = int(max_tokens)\n",
    "print(\"전체 문장의 {}%가 maxlen값 이내에 포함됩니다.\".format(np.sum(num_tokens<max_tokens)/len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb3497f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                       maxlen=maxlen)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                        value = word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                       maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "16c5df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:30000]\n",
    "y_val = y_train[:30000]\n",
    "X_train = X_train[30000:]\n",
    "y_train = y_train[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b51c724",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3962/2772009982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#단어사전에 존재하는 단어별 워드 벡터를 복사합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "vocab_size = 25000\n",
    "word_vector_dim = 200\n",
    "epochs = 4\n",
    "embedding_matrix = np.random.rand(vocab_size,word_vector_dim)\n",
    "#단어사전에 존재하는 단어별 워드 벡터를 복사합니다.\n",
    "for i in range(vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]\n",
    "print(index_to_word[4])        \n",
    "print(embedding_matrix[4])\n",
    "print(word2vec[index_to_word[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fea97a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tf.keras.Sequential()\n",
    "final_model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))\n",
    "final_model.add(tf.keras.layers.LSTM(256))\n",
    "final_model.add(tf.keras.layers.Dense(16,activation='relu'))\n",
    "final_model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "05a3b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "227/227 [==============================] - 8s 29ms/step - loss: 0.5334 - accuracy: 0.7174 - val_loss: 0.3924 - val_accuracy: 0.8238\n",
      "Epoch 2/4\n",
      "227/227 [==============================] - 6s 28ms/step - loss: 0.3633 - accuracy: 0.8411 - val_loss: 0.3543 - val_accuracy: 0.8419\n",
      "Epoch 3/4\n",
      "227/227 [==============================] - 6s 28ms/step - loss: 0.3271 - accuracy: 0.8608 - val_loss: 0.3534 - val_accuracy: 0.8457\n",
      "Epoch 4/4\n",
      "227/227 [==============================] - 6s 28ms/step - loss: 0.2979 - accuracy: 0.8754 - val_loss: 0.3550 - val_accuracy: 0.8439\n"
     ]
    }
   ],
   "source": [
    "final_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "final_history = final_model.fit(X_train,\n",
    "                           y_train,\n",
    "                           epochs=epochs,\n",
    "                           batch_size = 512,\n",
    "                           validation_data=(X_val,y_val),\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d840ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3661 - accuracy: 0.8407\n",
      "모델의 정확도는 84% 입니다.\n"
     ]
    }
   ],
   "source": [
    "model_loss,model_acc = final_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"모델의 정확도는 {}% 입니다.\".format(int(model_acc*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d4d3b",
   "metadata": {},
   "source": [
    "# 회고 \n",
    "- 오늘 프로젝트동안 인상 깊었던 것은 LMS에서 패스푸드점을 예시로 든 비유와 gzip 오류입니다. \n",
    "- 오늘 가장 많이 만난 오류는 gzip과 관련된 오류였습니다. 대략 10번 이상은 만났습니다. \n",
    "\n",
    "stateful/stateless에 대해서 배우기 전,1. 같은 질문을 하는 음식점 직원과 계속해서 답변을 누적시켜 답변하는 손님을 비교했을 때, 일상에서의 상황을 생각하고 당연히 손님에게 문제가 있다고 생각했다.\n",
    "2. 하지만 직원이 기억하지 못해 손님이 연속해서 누적된 답변을 하는 것을 알 수 있었다. \n",
    "3. 정확도를 높이기 위해 post 대신 pre를 사용했다. 대략 20%가 차이 난다고 한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b227a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
